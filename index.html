<html>

  <head>
    <title>hadi alaa abd elhai</title>
  </head>

  <body>
    <center><h1>artificial intellgience </h1></center>
    <h2>artificial intellgience </h2>
    <p>is intelligence demonstrated by machines, unlike the natural intelligence displayed
      by humans and animals, which involves consciousness and emotionality. The
      distinction between the former and the latter categories is often revealed
      by the acronym chosen. 'Strong' AI is usually labelled as artificial general
      intelligence (AGI) while attempts to emulate 'natural' intelligence have
      been called artificial biological intelligence (ABI). Leading AI textbooks
      define the field as the study of "intelligent agents": any device that perceives
      its environment and takes actions that maximize its chance of achieving its
      goals.[3] Colloquially, the term "artificial intelligence" is often used
      to describe machines that mimic "cognitive" functions that humans associate
      with the human mind, such as "learning" and "problem solving<p>
    <center><img src= "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQJxQDAa1hgWe_vyhn-Texf1QY9jCgjgn2O8g&usqp=CAU"/></center>

    <h2>history of artificial intellgience </h2>
    <p>Thought-capable artificial beings appeared as storytelling devices in antiquity,[37]
      and have been common in fiction, as in Mary Shelley's Frankenstein or Karel
      Čapek's R.U.R.[38] These characters and their fates raised many of the same
      issues now discussed in the ethics of artificial intelligence</p>
     <p>The study of mechanical or "formal" reasoning began with philosophers and mathematicians in antiquity. The study of mathematical logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as "0" and "1", could simulate any conceivable act of mathematical deduction. This insight, that digital computers can simulate any process of formal reasoning, is known as the Church–Turing thesis.[39] Along with concurrent discoveries in neurobiology, information theory and cybernetics, this led researchers to consider the possibility of building an electronic brain. Turing proposed changing the question from whether a machine was intelligent, to "whether or not it is possible for machinery to show intelligent behaviour".[40] The first work that is now generally recognized as AI was McCullouch and Pitts' 1943 formal design for Turing-complete "artificial neurons</p>
     <center><img src= "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTIGd42qNpbSMF5ylVGUTKP2HYq_30NVGzZtA&usqp=CAU"/></center>
     <h2>Applications on artificial intellgience</h2>
     <p>AI is relevant to any intellectual task.[192] Modern artificial intelligence techniques are pervasive[193] and are too numerous to list here. Frequently, when a technique reaches mainstream use, it is no longer considered artificial intelligence; this phenomenon is described as the AI effect.[194]
High-profile examples of AI include autonomous vehicles (such as drones and self-driving cars), medical diagnosis, creating art (such as poetry), proving mathematical theorems, playing games (such as Chess or Go), search engines (such as Google Search), online assistants (such as Siri), image recognition in photographs, spam filtering, predicting flight delays,[195] prediction of judicial decisions,[196] targeting online advertisements, [192][197][198] and energy storage[1</p>

  </body>
<html>

